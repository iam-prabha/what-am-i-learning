{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abdbb6c3-3370-4907-b8d2-18048f4c9a91",
   "metadata": {},
   "source": [
    "# import Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3f48b4-0f09-4aff-8806-13f8b75661f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4fff18-8835-478b-8d08-fd6cad6da636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sample messy dataset\n",
    "data = {\n",
    "    'Name': ['John','Alice', 'Bob', 'Emma', np.nan],\n",
    "    'Age' : [20, 999, 30, -5, 28],\n",
    "    'Salary': [50000, 60000, np.nan, 45000, 55000],\n",
    "    'Date': ['2023-01-01', '2023/02/30', '2023-03-15', '2023-04-01', '2023-05-01'],\n",
    "    'Department': ['IT', 'HR', 'IT', 'Sales', 'HR']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51d9395d-4193-48cf-98be-320bbd54bc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original messy data: \n",
      "    Name  Age   Salary        Date Department\n",
      "0   John   20  50000.0  2023-01-01         IT\n",
      "1  Alice  999  60000.0  2023/02/30         HR\n",
      "2    Bob   30      NaN  2023-03-15         IT\n",
      "3   Emma   -5  45000.0  2023-04-01      Sales\n",
      "4    NaN   28  55000.0  2023-05-01         HR\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "print(f'Original messy data: ')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd6cd4-35a9-4cdc-9f2c-f57321bd77b9",
   "metadata": {},
   "source": [
    "# step 1 - Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5356d7f-7ed8-4c93-b9c2-6af8d334962e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values count:\n",
      "Name          1\n",
      "Age           0\n",
      "Salary        1\n",
      "Date          0\n",
      "Department    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify missing values\n",
    "print(\"\\nMissing values count:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0978c717-766d-423f-8874-55b48439da11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After dropping NA:\n",
      "    Name  Age   Salary        Date Department\n",
      "0   John   20  50000.0  2023-01-01         IT\n",
      "1  Alice  999  60000.0  2023/02/30         HR\n",
      "3   Emma   -5  45000.0  2023-04-01      Sales\n",
      "\n",
      "After filling NA:\n",
      "      Name  Age   Salary        Date Department\n",
      "0     John   20  50000.0  2023-01-01         IT\n",
      "1    Alice  999  60000.0  2023/02/30         HR\n",
      "2      Bob   30  52500.0  2023-03-15         IT\n",
      "3     Emma   -5  45000.0  2023-04-01      Sales\n",
      "4  unknown   28  55000.0  2023-05-01         HR\n",
      "\n",
      "After forward fill:\n",
      "    Name  Age   Salary        Date Department\n",
      "0   John   20  50000.0  2023-01-01         IT\n",
      "1  Alice  999  60000.0  2023/02/30         HR\n",
      "2    Bob   30  60000.0  2023-03-15         IT\n",
      "3   Emma   -5  45000.0  2023-04-01      Sales\n",
      "4   Emma   28  55000.0  2023-05-01         HR\n"
     ]
    }
   ],
   "source": [
    "# Strategies for handling missing values:\n",
    "\n",
    "# a) Drop rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "print(\"\\nAfter dropping NA:\")\n",
    "print(df_dropped)\n",
    "\n",
    "# b) Fill with a specific value\n",
    "df_filled = df.copy()\n",
    "df_filled['Name'] = df_filled['Name'].fillna('unknown')\n",
    "df_filled['Salary'] = df_filled['Salary'].fillna(df_filled['Salary'].mean())\n",
    "print(\"\\nAfter filling NA:\")\n",
    "print(df_filled)\n",
    "\n",
    "# c) Forward fill or backward fill\n",
    "df_ffill = df.copy()\n",
    "df_ffill = df_ffill.ffill()\n",
    "print(\"\\nAfter forward fill:\")\n",
    "print(df_ffill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0954e0-79b8-44c4-ba67-5b7cc16e1e85",
   "metadata": {},
   "source": [
    "# step 2 - Handling Outliners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73702963-58f8-4940-8e88-1a2a452bc493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Age outliers:\n",
      "1    999\n",
      "3     -5\n",
      "Name: Age, dtype: int64\n",
      "\n",
      "Salary outliers:\n",
      "Series([], Name: Salary, dtype: float64)\n",
      "\n",
      "After handling outliers:\n",
      "    Name  Age   Salary        Date Department\n",
      "0   John   20  50000.0  2023-01-01         IT\n",
      "1  Alice  100  60000.0  2023/02/30         HR\n",
      "2    Bob   30      NaN  2023-03-15         IT\n",
      "3   Emma    0  45000.0  2023-04-01      Sales\n",
      "4    NaN   28  55000.0  2023-05-01         HR\n"
     ]
    }
   ],
   "source": [
    "# Detect outliers using IQR method\n",
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)][column]\n",
    "    return outliers\n",
    "\n",
    "# Check for outliers in Age and Salary\n",
    "print(\"\\nAge outliers:\")\n",
    "print(detect_outliers(df, 'Age'))\n",
    "print(\"\\nSalary outliers:\")\n",
    "print(detect_outliers(df, 'Salary'))\n",
    "\n",
    "# Handle outliers\n",
    "df_clean = df.copy()\n",
    "# Cap extreme values\n",
    "df_clean['Age'] = df_clean['Age'].clip(lower=0, upper=100)\n",
    "df_clean['Salary'] = df_clean['Salary'].clip(lower=0, upper=100000)\n",
    "print(\"\\nAfter handling outliers:\")\n",
    "print(df_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9689f5e7-60d8-4b08-adeb-c376aac7c9fa",
   "metadata": {},
   "source": [
    "# step 3 - Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d31a5be9-c00c-4aae-92d6-4bc09edf37df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After date conversion:\n",
      "    Name  Age   Salary       Date Department\n",
      "0   John   20  50000.0 2023-01-01         IT\n",
      "1  Alice  100  60000.0        NaT         HR\n",
      "2    Bob   30      NaN 2023-03-15         IT\n",
      "3   Emma    0  45000.0 2023-04-01      Sales\n",
      "4    NaN   28  55000.0 2023-05-01         HR\n",
      "\n",
      "After standardization:\n",
      "    Name  Age   Salary       Date Department  Salary_standardized\n",
      "0   John   20  50000.0 2023-01-01         IT            -0.387298\n",
      "1  Alice  100  60000.0        NaT         HR             1.161895\n",
      "2    Bob   30      NaN 2023-03-15         IT                  NaN\n",
      "3   Emma    0  45000.0 2023-04-01      Sales            -1.161895\n",
      "4    NaN   28  55000.0 2023-05-01         HR             0.387298\n",
      "\n",
      "After normalization:\n",
      "    Name  Age   Salary       Date Department  Salary_standardized  \\\n",
      "0   John   20  50000.0 2023-01-01         IT            -0.387298   \n",
      "1  Alice  100  60000.0        NaT         HR             1.161895   \n",
      "2    Bob   30      NaN 2023-03-15         IT                  NaN   \n",
      "3   Emma    0  45000.0 2023-04-01      Sales            -1.161895   \n",
      "4    NaN   28  55000.0 2023-05-01         HR             0.387298   \n",
      "\n",
      "   Salary_normalized  \n",
      "0           0.333333  \n",
      "1           1.000000  \n",
      "2                NaN  \n",
      "3           0.000000  \n",
      "4           0.666667  \n",
      "\n",
      "After one-hot encoding:\n",
      "    Name  Age   Salary       Date  Salary_standardized  Salary_normalized  \\\n",
      "0   John   20  50000.0 2023-01-01            -0.387298           0.333333   \n",
      "1  Alice  100  60000.0        NaT             1.161895           1.000000   \n",
      "2    Bob   30      NaN 2023-03-15                  NaN                NaN   \n",
      "3   Emma    0  45000.0 2023-04-01            -1.161895           0.000000   \n",
      "4    NaN   28  55000.0 2023-05-01             0.387298           0.666667   \n",
      "\n",
      "   Dept_HR  Dept_IT  Dept_Sales  \n",
      "0    False     True       False  \n",
      "1     True    False       False  \n",
      "2    False     True       False  \n",
      "3    False    False        True  \n",
      "4     True    False       False  \n",
      "\n",
      "After label encoding:\n",
      "    Name  Age   Salary       Date Department  Salary_standardized  \\\n",
      "0   John   20  50000.0 2023-01-01         IT            -0.387298   \n",
      "1  Alice  100  60000.0        NaT         HR             1.161895   \n",
      "2    Bob   30      NaN 2023-03-15         IT                  NaN   \n",
      "3   Emma    0  45000.0 2023-04-01      Sales            -1.161895   \n",
      "4    NaN   28  55000.0 2023-05-01         HR             0.387298   \n",
      "\n",
      "   Salary_normalized  Department_encoded  \n",
      "0           0.333333                   1  \n",
      "1           1.000000                   0  \n",
      "2                NaN                   1  \n",
      "3           0.000000                   2  \n",
      "4           0.666667                   0  \n"
     ]
    }
   ],
   "source": [
    "# Convert Date column to datetime\n",
    "df_clean['Date'] = pd.to_datetime(df_clean['Date'], errors='coerce')\n",
    "print(\"\\nAfter date conversion:\")\n",
    "print(df_clean)\n",
    "\n",
    "# Standardize numerical columns\n",
    "def standardize_column(series):\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "df_clean['Salary_standardized'] = standardize_column(df_clean['Salary'])\n",
    "print(\"\\nAfter standardization:\")\n",
    "print(df_clean)\n",
    "\n",
    "# Normalize numerical columns (0 to 1 scale)\n",
    "def normalize_column(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "df_clean['Salary_normalized'] = normalize_column(df_clean['Salary'])\n",
    "print(\"\\nAfter normalization:\")\n",
    "print(df_clean)\n",
    "\n",
    "# Encode categorical variables\n",
    "# One-hot encoding\n",
    "df_encoded = pd.get_dummies(df_clean, columns=['Department'], prefix='Dept')\n",
    "print(\"\\nAfter one-hot encoding:\")\n",
    "print(df_encoded)\n",
    "\n",
    "# Label encoding alternative\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_clean['Department_encoded'] = le.fit_transform(df_clean['Department'].astype(str))\n",
    "print(\"\\nAfter label encoding:\")\n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e793609-4da8-46f0-b438-878fec6eab53",
   "metadata": {},
   "source": [
    "# Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1264d5bc-1ad0-4dd8-a4ae-cf35980a5430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final cleaned dataset:\n",
      "      Name  Age   Salary       Date  Salary_standardized  Dept_HR  Dept_IT  \\\n",
      "0     John   20  50000.0 2023-01-01            -0.447214    False     True   \n",
      "1    Alice  100  60000.0        NaT             1.341641     True    False   \n",
      "2      Bob   30  52500.0 2023-03-15             0.000000    False     True   \n",
      "3     Emma    0  45000.0 2023-04-01            -1.341641    False    False   \n",
      "4  Unknown   28  55000.0 2023-05-01             0.447214     True    False   \n",
      "\n",
      "   Dept_Sales  \n",
      "0       False  \n",
      "1       False  \n",
      "2       False  \n",
      "3        True  \n",
      "4       False  \n"
     ]
    }
   ],
   "source": [
    "def clean_dataset(df):\n",
    "    # Create a copy to avoid modifying original\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    df_cleaned['Name'] = df_cleaned['Name'].fillna('Unknown')\n",
    "    df_cleaned['Salary'] = df_cleaned['Salary'].fillna(df_cleaned['Salary'].median())\n",
    "    \n",
    "    # Handle outliers\n",
    "    df_cleaned['Age'] = df_cleaned['Age'].clip(lower=0, upper=100)\n",
    "    df_cleaned['Salary'] = df_cleaned['Salary'].clip(lower=0, upper=100000)\n",
    "    \n",
    "    # Transform data\n",
    "    df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'], errors='coerce')\n",
    "    df_cleaned['Salary_standardized'] = standardize_column(df_cleaned['Salary'])\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    df_cleaned = pd.get_dummies(df_cleaned, columns=['Department'], prefix='Dept')\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# Apply cleaning function\n",
    "cleaned_df = clean_dataset(df)\n",
    "print(\"\\nFinal cleaned dataset:\")\n",
    "print(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7316be64-8e9a-4602-b86f-71e3aff5ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name           object\n",
      "Age             int64\n",
      "Salary        float64\n",
      "Date           object\n",
      "Department     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert data types if needed\n",
    "df['Age'] = df['Age'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f19de05e-64d2-4787-8154-22f4a3389a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove whitespace and standardize string format\n",
    "df['Name'] = df['Name'].str.strip().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04ab753d-1f9a-4fbe-a5e0-abaf1995c2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Check and remove duplicates\n",
    "print(f\"Number of duplicates: {df.duplicated().sum()}\")\n",
    "df_no_duplicates = df.drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
